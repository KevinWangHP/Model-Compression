==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
==> Preparing the model for binarization
ResNet(
  (conv1): Conv2d(
    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
    (activation_pre_process): Identity()
    (activation_post_process): Identity()
    (weight_pre_process): Identity()
  )
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ReLU(inplace=True)
      (act2): ReLU(inplace=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ReLU(inplace=True)
      (act2): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ReLU(inplace=True)
      (act2): ReLU(inplace=True)
      (downsample): Sequential(
        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (1): Conv2d(
          64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (activation_pre_process): BasicInputBinarizer()
          (activation_post_process): Identity()
          (weight_pre_process): XNORWeightBinarizer()
        )
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ReLU(inplace=True)
      (act2): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(
        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ReLU(inplace=True)
      (act2): ReLU(inplace=True)
      (downsample): Sequential(
        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (1): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (activation_pre_process): BasicInputBinarizer()
          (activation_post_process): Identity()
          (weight_pre_process): XNORWeightBinarizer()
        )
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ReLU(inplace=True)
      (act2): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(
        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ReLU(inplace=True)
      (act2): ReLU(inplace=True)
      (downsample): Sequential(
        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (1): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (activation_pre_process): BasicInputBinarizer()
          (activation_post_process): Identity()
          (weight_pre_process): XNORWeightBinarizer()
        )
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(
        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (activation_pre_process): BasicInputBinarizer()
        (activation_post_process): Identity()
        (weight_pre_process): XNORWeightBinarizer()
      )
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act1): ReLU(inplace=True)
      (act2): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(
    in_features=512, out_features=10, bias=True
    (activation_pre_process): Identity()
    (activation_post_process): Identity()
    (weight_pre_process): Identity()
  )
)

Train Epoch: 0
Epoch: [0][  0/391]	Time 14.093 (14.093)	Data  0.221 ( 0.221)	Loss 2.4006e+00 (2.4006e+00)	Acc@1  13.28 ( 13.28)
Epoch: [0][100/391]	Time  0.691 ( 0.393)	Data  0.001 ( 0.005)	Loss 1.8197e+00 (1.9887e+00)	Acc@1  38.28 ( 25.02)
Epoch: [0][200/391]	Time  0.142 ( 0.319)	Data  0.001 ( 0.004)	Loss 1.7936e+00 (1.8691e+00)	Acc@1  31.25 ( 29.99)
Epoch: [0][300/391]	Time  0.382 ( 0.300)	Data  0.001 ( 0.003)	Loss 1.6121e+00 (1.7913e+00)	Acc@1  37.50 ( 33.24)
Train acc: 35.232, Train loss: 1.745607533569336, Epoch time: 115.05878162384033
Test Epoch: [0][  0/100]	Time  0.870 ( 0.870)	Data  0.310 ( 0.310)	Loss 1.6134e+00 (1.6134e+00)	Acc@1  47.00 ( 47.00)
Saving...
Current acc: 40.02, Current loss: 1.7122984194755555, best acc: 40.02, Test time: 11.437032461166382

Train Epoch: 1
Epoch: [1][  0/391]	Time  0.405 ( 0.405)	Data  0.171 ( 0.171)	Loss 1.4439e+00 (1.4439e+00)	Acc@1  48.44 ( 48.44)
Epoch: [1][100/391]	Time  0.151 ( 0.276)	Data  0.002 ( 0.005)	Loss 1.4722e+00 (1.5134e+00)	Acc@1  47.66 ( 45.15)
Epoch: [1][200/391]	Time  0.445 ( 0.263)	Data  0.002 ( 0.004)	Loss 1.3161e+00 (1.4847e+00)	Acc@1  50.00 ( 46.01)
Epoch: [1][300/391]	Time  0.686 ( 0.260)	Data  0.002 ( 0.003)	Loss 1.5108e+00 (1.4649e+00)	Acc@1  49.22 ( 46.68)
Train acc: 47.75, Train loss: 1.4351967479324341, Epoch time: 100.37900996208191
Test Epoch: [1][  0/100]	Time  0.307 ( 0.307)	Data  0.246 ( 0.246)	Loss 1.1897e+00 (1.1897e+00)	Acc@1  57.00 ( 57.00)
Saving...
Current acc: 52.84, Current loss: 1.3220745837688446, best acc: 52.84, Test time: 10.916261434555054

Train Epoch: 2
Epoch: [2][  0/391]	Time  0.498 ( 0.498)	Data  0.267 ( 0.267)	Loss 1.2762e+00 (1.2762e+00)	Acc@1  56.25 ( 56.25)
Epoch: [2][100/391]	Time  0.149 ( 0.260)	Data  0.001 ( 0.005)	Loss 1.3074e+00 (1.2881e+00)	Acc@1  52.34 ( 53.68)
Epoch: [2][200/391]	Time  0.172 ( 0.263)	Data  0.002 ( 0.004)	Loss 1.1843e+00 (1.2731e+00)	Acc@1  57.03 ( 54.24)
Epoch: [2][300/391]	Time  0.233 ( 0.264)	Data  0.002 ( 0.003)	Loss 1.2896e+00 (1.2567e+00)	Acc@1  50.00 ( 54.81)
Train acc: 55.33, Train loss: 1.2412699321365357, Epoch time: 102.76166915893555
Test Epoch: [2][  0/100]	Time  0.326 ( 0.326)	Data  0.253 ( 0.253)	Loss 1.2762e+00 (1.2762e+00)	Acc@1  53.00 ( 53.00)
Saving...
Current acc: 56.82, Current loss: 1.2121263140439986, best acc: 56.82, Test time: 10.398917436599731

Train Epoch: 3
Epoch: [3][  0/391]	Time  0.383 ( 0.383)	Data  0.198 ( 0.198)	Loss 1.1297e+00 (1.1297e+00)	Acc@1  60.16 ( 60.16)
Epoch: [3][100/391]	Time  0.165 ( 0.244)	Data  0.002 ( 0.004)	Loss 1.2263e+00 (1.1410e+00)	Acc@1  50.00 ( 59.27)
Epoch: [3][200/391]	Time  0.150 ( 0.251)	Data  0.002 ( 0.004)	Loss 1.1821e+00 (1.1329e+00)	Acc@1  53.12 ( 59.45)
Epoch: [3][300/391]	Time  0.120 ( 0.253)	Data  0.001 ( 0.004)	Loss 1.0825e+00 (1.1204e+00)	Acc@1  54.69 ( 59.84)
Train acc: 60.134, Train loss: 1.112555851097107, Epoch time: 97.49974179267883
Test Epoch: [3][  0/100]	Time  0.210 ( 0.210)	Data  0.176 ( 0.176)	Loss 9.7370e-01 (9.7370e-01)	Acc@1  58.00 ( 58.00)
Saving...
Current acc: 62.72, Current loss: 1.0504070520401, best acc: 62.72, Test time: 10.395310401916504

Train Epoch: 4
Epoch: [4][  0/391]	Time  0.514 ( 0.514)	Data  0.295 ( 0.295)	Loss 9.7698e-01 (9.7698e-01)	Acc@1  68.75 ( 68.75)
Epoch: [4][100/391]	Time  0.154 ( 0.261)	Data  0.002 ( 0.006)	Loss 1.2222e+00 (1.0337e+00)	Acc@1  50.78 ( 63.07)
Epoch: [4][200/391]	Time  0.183 ( 0.256)	Data  0.013 ( 0.005)	Loss 8.2627e-01 (1.0321e+00)	Acc@1  69.53 ( 63.31)
Epoch: [4][300/391]	Time  0.191 ( 0.258)	Data  0.002 ( 0.004)	Loss 1.2366e+00 (1.0270e+00)	Acc@1  53.12 ( 63.30)
Train acc: 63.372, Train loss: 1.02275080991745, Epoch time: 101.168142080307
Test Epoch: [4][  0/100]	Time  0.341 ( 0.341)	Data  0.283 ( 0.283)	Loss 9.2428e-01 (9.2428e-01)	Acc@1  66.00 ( 66.00)
Saving...
Current acc: 62.74, Current loss: 1.0859797990322113, best acc: 62.74, Test time: 11.03296184539795

Train Epoch: 5
Epoch: [5][  0/391]	Time  0.423 ( 0.423)	Data  0.265 ( 0.265)	Loss 9.7141e-01 (9.7141e-01)	Acc@1  65.62 ( 65.62)
Epoch: [5][100/391]	Time  0.136 ( 0.255)	Data  0.001 ( 0.005)	Loss 9.6501e-01 (9.6426e-01)	Acc@1  69.53 ( 65.88)
Epoch: [5][200/391]	Time  0.188 ( 0.252)	Data  0.001 ( 0.004)	Loss 9.9517e-01 (9.6890e-01)	Acc@1  64.84 ( 65.74)
Epoch: [5][300/391]	Time  0.143 ( 0.253)	Data  0.001 ( 0.003)	Loss 9.0011e-01 (9.5850e-01)	Acc@1  64.06 ( 66.05)
Train acc: 66.146, Train loss: 0.9535668284797668, Epoch time: 100.15136241912842
Test Epoch: [5][  0/100]	Time  0.270 ( 0.270)	Data  0.224 ( 0.224)	Loss 7.6212e-01 (7.6212e-01)	Acc@1  74.00 ( 74.00)
Saving...
Current acc: 68.55, Current loss: 0.8985772597789764, best acc: 68.55, Test time: 10.973979473114014

Train Epoch: 6
Epoch: [6][  0/391]	Time  0.422 ( 0.422)	Data  0.219 ( 0.219)	Loss 9.6244e-01 (9.6244e-01)	Acc@1  69.53 ( 69.53)
Epoch: [6][100/391]	Time  0.207 ( 0.272)	Data  0.003 ( 0.004)	Loss 6.9499e-01 (9.0571e-01)	Acc@1  77.34 ( 67.57)
Epoch: [6][200/391]	Time  0.651 ( 0.275)	Data  0.001 ( 0.003)	Loss 8.3921e-01 (9.0779e-01)	Acc@1  68.75 ( 67.72)
Epoch: [6][300/391]	Time  0.289 ( 0.270)	Data  0.001 ( 0.003)	Loss 1.0180e+00 (9.0302e-01)	Acc@1  63.28 ( 68.07)
Train acc: 68.286, Train loss: 0.8996384780883789, Epoch time: 103.14930629730225
Test Epoch: [6][  0/100]	Time  0.253 ( 0.253)	Data  0.191 ( 0.191)	Loss 8.7489e-01 (8.7489e-01)	Acc@1  69.00 ( 69.00)
Current acc: 64.38, Current loss: 1.051877077817917, best acc: 68.55, Test time: 10.086127281188965

Train Epoch: 7
Epoch: [7][  0/391]	Time  0.389 ( 0.389)	Data  0.196 ( 0.196)	Loss 8.1606e-01 (8.1606e-01)	Acc@1  68.75 ( 68.75)
Epoch: [7][100/391]	Time  0.440 ( 0.252)	Data  0.002 ( 0.004)	Loss 7.4217e-01 (8.4961e-01)	Acc@1  76.56 ( 69.76)
Epoch: [7][200/391]	Time  0.214 ( 0.251)	Data  0.004 ( 0.003)	Loss 7.4452e-01 (8.4765e-01)	Acc@1  67.97 ( 69.62)
Epoch: [7][300/391]	Time  0.269 ( 0.248)	Data  0.002 ( 0.003)	Loss 7.1414e-01 (8.5125e-01)	Acc@1  74.22 ( 69.50)
Train acc: 69.516, Train loss: 0.8548245323371887, Epoch time: 96.6121244430542
Test Epoch: [7][  0/100]	Time  0.204 ( 0.204)	Data  0.153 ( 0.153)	Loss 9.2452e-01 (9.2452e-01)	Acc@1  64.00 ( 64.00)
Current acc: 64.82, Current loss: 1.032184322476387, best acc: 68.55, Test time: 9.526003122329712

Train Epoch: 8
Epoch: [8][  0/391]	Time  0.941 ( 0.941)	Data  0.194 ( 0.194)	Loss 8.0602e-01 (8.0602e-01)	Acc@1  70.31 ( 70.31)
Epoch: [8][100/391]	Time  0.210 ( 0.262)	Data  0.001 ( 0.004)	Loss 6.6244e-01 (8.1655e-01)	Acc@1  78.91 ( 71.01)
Epoch: [8][200/391]	Time  0.244 ( 0.258)	Data  0.002 ( 0.003)	Loss 6.9572e-01 (8.1772e-01)	Acc@1  75.00 ( 71.14)
Epoch: [8][300/391]	Time  0.179 ( 0.252)	Data  0.002 ( 0.003)	Loss 8.8512e-01 (8.1798e-01)	Acc@1  68.75 ( 71.25)
Train acc: 71.374, Train loss: 0.8128525131607056, Epoch time: 97.51086068153381
Test Epoch: [8][  0/100]	Time  0.280 ( 0.280)	Data  0.202 ( 0.202)	Loss 8.6456e-01 (8.6456e-01)	Acc@1  68.00 ( 68.00)
Saving...
Current acc: 69.32, Current loss: 0.8757669317722321, best acc: 69.32, Test time: 9.593405723571777

Train Epoch: 9
Epoch: [9][  0/391]	Time  0.823 ( 0.823)	Data  0.191 ( 0.191)	Loss 8.1943e-01 (8.1943e-01)	Acc@1  71.88 ( 71.88)
Epoch: [9][100/391]	Time  0.161 ( 0.251)	Data  0.002 ( 0.004)	Loss 6.5412e-01 (7.8054e-01)	Acc@1  76.56 ( 72.18)
Epoch: [9][200/391]	Time  0.157 ( 0.250)	Data  0.003 ( 0.003)	Loss 7.2594e-01 (7.8152e-01)	Acc@1  74.22 ( 72.14)
Epoch: [9][300/391]	Time  0.149 ( 0.247)	Data  0.001 ( 0.003)	Loss 7.5075e-01 (7.7736e-01)	Acc@1  73.44 ( 72.37)
Train acc: 72.584, Train loss: 0.7721008200454712, Epoch time: 96.39327716827393
Test Epoch: [9][  0/100]	Time  0.266 ( 0.266)	Data  0.220 ( 0.220)	Loss 6.7583e-01 (6.7583e-01)	Acc@1  80.00 ( 80.00)
Saving...
Current acc: 71.06, Current loss: 0.8336942604184151, best acc: 71.06, Test time: 9.872625827789307

Train Epoch: 10
Epoch: [10][  0/391]	Time  0.433 ( 0.433)	Data  0.291 ( 0.291)	Loss 7.0668e-01 (7.0668e-01)	Acc@1  75.78 ( 75.78)
Epoch: [10][100/391]	Time  0.132 ( 0.249)	Data  0.002 ( 0.005)	Loss 7.4740e-01 (7.4061e-01)	Acc@1  71.88 ( 73.65)
Epoch: [10][200/391]	Time  0.150 ( 0.243)	Data  0.001 ( 0.004)	Loss 7.6222e-01 (7.4115e-01)	Acc@1  72.66 ( 74.00)
Epoch: [10][300/391]	Time  0.402 ( 0.243)	Data  0.001 ( 0.003)	Loss 9.4375e-01 (7.4375e-01)	Acc@1  64.06 ( 73.79)
Train acc: 73.534, Train loss: 0.7459069107627868, Epoch time: 95.39814972877502
Test Epoch: [10][  0/100]	Time  0.325 ( 0.325)	Data  0.249 ( 0.249)	Loss 5.8058e-01 (5.8058e-01)	Acc@1  79.00 ( 79.00)
Saving...
Current acc: 72.95, Current loss: 0.7767455399036407, best acc: 72.95, Test time: 9.292033910751343

Train Epoch: 11
Epoch: [11][  0/391]	Time  0.533 ( 0.533)	Data  0.347 ( 0.347)	Loss 7.4289e-01 (7.4289e-01)	Acc@1  74.22 ( 74.22)
Epoch: [11][100/391]	Time  0.175 ( 0.252)	Data  0.002 ( 0.006)	Loss 6.0451e-01 (7.2913e-01)	Acc@1  82.03 ( 74.32)
Epoch: [11][200/391]	Time  0.157 ( 0.253)	Data  0.001 ( 0.004)	Loss 6.7830e-01 (7.1603e-01)	Acc@1  75.78 ( 74.86)
Epoch: [11][300/391]	Time  0.292 ( 0.247)	Data  0.002 ( 0.003)	Loss 6.7954e-01 (7.1343e-01)	Acc@1  77.34 ( 74.99)
Train acc: 75.074, Train loss: 0.7084028793907166, Epoch time: 97.97369289398193
Test Epoch: [11][  0/100]	Time  0.328 ( 0.328)	Data  0.269 ( 0.269)	Loss 7.2508e-01 (7.2508e-01)	Acc@1  75.00 ( 75.00)
Current acc: 70.66, Current loss: 0.8701087069511414, best acc: 72.95, Test time: 9.255825757980347

Train Epoch: 12
Epoch: [12][  0/391]	Time  0.905 ( 0.905)	Data  0.217 ( 0.217)	Loss 6.5190e-01 (6.5190e-01)	Acc@1  82.81 ( 82.81)
Epoch: [12][100/391]	Time  0.158 ( 0.262)	Data  0.002 ( 0.004)	Loss 5.7227e-01 (6.6686e-01)	Acc@1  80.47 ( 76.39)
Epoch: [12][200/391]	Time  0.288 ( 0.264)	Data  0.003 ( 0.003)	Loss 5.5806e-01 (6.6402e-01)	Acc@1  81.25 ( 76.53)
Epoch: [12][300/391]	Time  0.738 ( 0.260)	Data  0.003 ( 0.003)	Loss 8.2727e-01 (6.6772e-01)	Acc@1  73.44 ( 76.47)
Train acc: 76.404, Train loss: 0.6711679053497315, Epoch time: 100.62501764297485
Test Epoch: [12][  0/100]	Time  0.279 ( 0.279)	Data  0.203 ( 0.203)	Loss 4.9768e-01 (4.9768e-01)	Acc@1  80.00 ( 80.00)
Saving...
Current acc: 77.38, Current loss: 0.6448691591620446, best acc: 77.38, Test time: 10.295738697052002

Train Epoch: 13
Epoch: [13][  0/391]	Time  0.662 ( 0.662)	Data  0.190 ( 0.190)	Loss 7.8702e-01 (7.8702e-01)	Acc@1  74.22 ( 74.22)
Epoch: [13][100/391]	Time  0.291 ( 0.243)	Data  0.002 ( 0.004)	Loss 7.7900e-01 (6.4653e-01)	Acc@1  73.44 ( 77.18)
Epoch: [13][200/391]	Time  0.166 ( 0.246)	Data  0.001 ( 0.003)	Loss 5.3973e-01 (6.4560e-01)	Acc@1  81.25 ( 77.37)
Epoch: [13][300/391]	Time  0.247 ( 0.251)	Data  0.005 ( 0.003)	Loss 7.0548e-01 (6.4691e-01)	Acc@1  71.88 ( 77.34)
Train acc: 77.434, Train loss: 0.643356035194397, Epoch time: 99.79394459724426
Test Epoch: [13][  0/100]	Time  0.329 ( 0.329)	Data  0.246 ( 0.246)	Loss 7.4968e-01 (7.4968e-01)	Acc@1  72.00 ( 72.00)
Current acc: 73.38, Current loss: 0.7873019486665725, best acc: 77.38, Test time: 9.752419471740723

Train Epoch: 14
Epoch: [14][  0/391]	Time  0.486 ( 0.486)	Data  0.260 ( 0.260)	Loss 4.9728e-01 (4.9728e-01)	Acc@1  78.12 ( 78.12)
Epoch: [14][100/391]	Time  0.238 ( 0.258)	Data  0.004 ( 0.005)	Loss 5.9461e-01 (6.2252e-01)	Acc@1  77.34 ( 78.04)
Epoch: [14][200/391]	Time  0.198 ( 0.259)	Data  0.002 ( 0.004)	Loss 7.1158e-01 (6.2915e-01)	Acc@1  75.78 ( 77.83)
Epoch: [14][300/391]	Time  0.213 ( 0.257)	Data  0.002 ( 0.003)	Loss 6.4545e-01 (6.2820e-01)	Acc@1  79.69 ( 77.85)
Train acc: 77.966, Train loss: 0.6267946170425415, Epoch time: 100.3863205909729
Test Epoch: [14][  0/100]	Time  0.260 ( 0.260)	Data  0.215 ( 0.215)	Loss 7.5723e-01 (7.5723e-01)	Acc@1  69.00 ( 69.00)
Current acc: 74.52, Current loss: 0.7415980419516564, best acc: 77.38, Test time: 10.630313873291016

Train Epoch: 15
Epoch: [15][  0/391]	Time  0.543 ( 0.543)	Data  0.239 ( 0.239)	Loss 5.6991e-01 (5.6991e-01)	Acc@1  81.25 ( 81.25)
Epoch: [15][100/391]	Time  0.228 ( 0.242)	Data  0.002 ( 0.005)	Loss 5.6150e-01 (5.9105e-01)	Acc@1  81.25 ( 79.35)
Epoch: [15][200/391]	Time  0.467 ( 0.244)	Data  0.004 ( 0.004)	Loss 6.0033e-01 (5.9473e-01)	Acc@1  78.12 ( 79.01)
Epoch: [15][300/391]	Time  0.489 ( 0.244)	Data  0.001 ( 0.003)	Loss 5.1770e-01 (5.9423e-01)	Acc@1  85.16 ( 79.13)
Train acc: 79.128, Train loss: 0.594888561592102, Epoch time: 95.64888715744019
Test Epoch: [15][  0/100]	Time  0.296 ( 0.296)	Data  0.255 ( 0.255)	Loss 7.7037e-01 (7.7037e-01)	Acc@1  73.00 ( 73.00)
Current acc: 75.57, Current loss: 0.7092224237322807, best acc: 77.38, Test time: 10.252689123153687

Train Epoch: 16
Epoch: [16][  0/391]	Time  0.387 ( 0.387)	Data  0.248 ( 0.248)	Loss 7.3476e-01 (7.3476e-01)	Acc@1  72.66 ( 72.66)
Epoch: [16][100/391]	Time  0.161 ( 0.253)	Data  0.002 ( 0.005)	Loss 7.3416e-01 (5.6801e-01)	Acc@1  73.44 ( 80.42)
Epoch: [16][200/391]	Time  0.193 ( 0.253)	Data  0.002 ( 0.004)	Loss 6.9326e-01 (5.7337e-01)	Acc@1  76.56 ( 80.08)
Epoch: [16][300/391]	Time  0.128 ( 0.257)	Data  0.004 ( 0.003)	Loss 5.8534e-01 (5.7643e-01)	Acc@1  75.78 ( 79.91)
Train acc: 79.886, Train loss: 0.5756287600135803, Epoch time: 99.84601736068726
Test Epoch: [16][  0/100]	Time  0.271 ( 0.271)	Data  0.216 ( 0.216)	Loss 5.3369e-01 (5.3369e-01)	Acc@1  79.00 ( 79.00)
Saving...
Current acc: 79.74, Current loss: 0.6110830131173134, best acc: 79.74, Test time: 9.75244426727295

Train Epoch: 17
Epoch: [17][  0/391]	Time  1.073 ( 1.073)	Data  0.294 ( 0.294)	Loss 6.3984e-01 (6.3984e-01)	Acc@1  79.69 ( 79.69)
Epoch: [17][100/391]	Time  0.120 ( 0.255)	Data  0.002 ( 0.005)	Loss 4.5377e-01 (5.6024e-01)	Acc@1  86.72 ( 80.51)
Epoch: [17][200/391]	Time  0.293 ( 0.249)	Data  0.001 ( 0.004)	Loss 6.7234e-01 (5.6122e-01)	Acc@1  80.47 ( 80.43)
Epoch: [17][300/391]	Time  0.620 ( 0.246)	Data  0.002 ( 0.003)	Loss 5.9621e-01 (5.5939e-01)	Acc@1  78.91 ( 80.39)
Train acc: 80.2, Train loss: 0.5639731150436401, Epoch time: 96.55795955657959
Test Epoch: [17][  0/100]	Time  0.290 ( 0.290)	Data  0.234 ( 0.234)	Loss 5.4610e-01 (5.4610e-01)	Acc@1  79.00 ( 79.00)
Current acc: 76.89, Current loss: 0.6885639330744744, best acc: 79.74, Test time: 9.33384919166565

Train Epoch: 18
Epoch: [18][  0/391]	Time  0.694 ( 0.694)	Data  0.275 ( 0.275)	Loss 6.8287e-01 (6.8287e-01)	Acc@1  75.78 ( 75.78)
Epoch: [18][100/391]	Time  0.141 ( 0.243)	Data  0.002 ( 0.005)	Loss 5.2749e-01 (5.4936e-01)	Acc@1  81.25 ( 80.53)
Epoch: [18][200/391]	Time  0.682 ( 0.248)	Data  0.002 ( 0.004)	Loss 4.3750e-01 (5.4517e-01)	Acc@1  81.25 ( 80.91)
Epoch: [18][300/391]	Time  0.422 ( 0.247)	Data  0.002 ( 0.003)	Loss 6.5848e-01 (5.4533e-01)	Acc@1  78.12 ( 81.03)
Train acc: 81.128, Train loss: 0.542034132194519, Epoch time: 97.32240056991577
Test Epoch: [18][  0/100]	Time  0.299 ( 0.299)	Data  0.247 ( 0.247)	Loss 5.6445e-01 (5.6445e-01)	Acc@1  79.00 ( 79.00)
Current acc: 79.45, Current loss: 0.6242147433757782, best acc: 79.74, Test time: 9.313161134719849

Train Epoch: 19
Epoch: [19][  0/391]	Time  0.419 ( 0.419)	Data  0.224 ( 0.224)	Loss 5.7524e-01 (5.7524e-01)	Acc@1  76.56 ( 76.56)
Epoch: [19][100/391]	Time  0.130 ( 0.243)	Data  0.002 ( 0.005)	Loss 5.2870e-01 (5.2564e-01)	Acc@1  85.16 ( 81.32)
Epoch: [19][200/391]	Time  0.149 ( 0.243)	Data  0.002 ( 0.004)	Loss 4.6622e-01 (5.3316e-01)	Acc@1  85.94 ( 81.27)
Epoch: [19][300/391]	Time  0.129 ( 0.244)	Data  0.001 ( 0.003)	Loss 6.2643e-01 (5.3360e-01)	Acc@1  77.34 ( 81.33)
Train acc: 81.47, Train loss: 0.5312688546943665, Epoch time: 95.60085034370422
Test Epoch: [19][  0/100]	Time  0.294 ( 0.294)	Data  0.252 ( 0.252)	Loss 4.5553e-01 (4.5553e-01)	Acc@1  83.00 ( 83.00)
Saving...
Current acc: 80.79, Current loss: 0.5508914890885354, best acc: 80.79, Test time: 9.482551336288452

Train Epoch: 20
Epoch: [20][  0/391]	Time  0.931 ( 0.931)	Data  0.313 ( 0.313)	Loss 4.2451e-01 (4.2451e-01)	Acc@1  82.81 ( 82.81)
Epoch: [20][100/391]	Time  0.133 ( 0.254)	Data  0.001 ( 0.006)	Loss 3.6808e-01 (5.1026e-01)	Acc@1  88.28 ( 82.22)
Epoch: [20][200/391]	Time  0.199 ( 0.246)	Data  0.002 ( 0.004)	Loss 5.2905e-01 (5.0822e-01)	Acc@1  82.81 ( 82.28)
Epoch: [20][300/391]	Time  0.157 ( 0.241)	Data  0.002 ( 0.004)	Loss 6.3418e-01 (5.1519e-01)	Acc@1  79.69 ( 82.01)
Train acc: 81.926, Train loss: 0.5146868019294739, Epoch time: 94.23761534690857
Test Epoch: [20][  0/100]	Time  0.305 ( 0.305)	Data  0.237 ( 0.237)	Loss 4.4138e-01 (4.4138e-01)	Acc@1  84.00 ( 84.00)
Saving...
Current acc: 81.64, Current loss: 0.5470560309290886, best acc: 81.64, Test time: 9.9022798538208

Train Epoch: 21
Epoch: [21][  0/391]	Time  0.562 ( 0.562)	Data  0.280 ( 0.280)	Loss 4.3357e-01 (4.3357e-01)	Acc@1  84.38 ( 84.38)
Epoch: [21][100/391]	Time  0.162 ( 0.246)	Data  0.001 ( 0.005)	Loss 6.5095e-01 (5.0307e-01)	Acc@1  77.34 ( 82.07)
Epoch: [21][200/391]	Time  0.187 ( 0.248)	Data  0.002 ( 0.004)	Loss 4.6448e-01 (5.0439e-01)	Acc@1  84.38 ( 82.25)
Epoch: [21][300/391]	Time  0.382 ( 0.249)	Data  0.002 ( 0.003)	Loss 4.1376e-01 (5.0912e-01)	Acc@1  82.81 ( 82.01)
Train acc: 82.1, Train loss: 0.5081539780521392, Epoch time: 97.71867275238037
Test Epoch: [21][  0/100]	Time  0.341 ( 0.341)	Data  0.260 ( 0.260)	Loss 5.1612e-01 (5.1612e-01)	Acc@1  85.00 ( 85.00)
Saving...
Current acc: 82.38, Current loss: 0.5205182737112045, best acc: 82.38, Test time: 10.778003692626953

Train Epoch: 22
Epoch: [22][  0/391]	Time  0.575 ( 0.575)	Data  0.346 ( 0.346)	Loss 5.0195e-01 (5.0195e-01)	Acc@1  82.81 ( 82.81)
Epoch: [22][100/391]	Time  0.175 ( 0.244)	Data  0.001 ( 0.005)	Loss 5.2293e-01 (4.8349e-01)	Acc@1  82.81 ( 83.05)
Epoch: [22][200/391]	Time  0.132 ( 0.248)	Data  0.002 ( 0.004)	Loss 5.9999e-01 (4.8211e-01)	Acc@1  79.69 ( 83.15)
Epoch: [22][300/391]	Time  0.154 ( 0.250)	Data  0.002 ( 0.003)	Loss 5.8641e-01 (4.9100e-01)	Acc@1  82.03 ( 82.75)
Train acc: 82.706, Train loss: 0.49292236707687376, Epoch time: 97.79124999046326
Test Epoch: [22][  0/100]	Time  0.219 ( 0.219)	Data  0.167 ( 0.167)	Loss 4.5352e-01 (4.5352e-01)	Acc@1  81.00 ( 81.00)
Current acc: 82.11, Current loss: 0.5248033630847931, best acc: 82.38, Test time: 10.097012758255005

Train Epoch: 23
Epoch: [23][  0/391]	Time  0.447 ( 0.447)	Data  0.294 ( 0.294)	Loss 4.6278e-01 (4.6278e-01)	Acc@1  85.94 ( 85.94)
Epoch: [23][100/391]	Time  0.410 ( 0.276)	Data  0.001 ( 0.005)	Loss 3.4286e-01 (4.8099e-01)	Acc@1  89.06 ( 83.16)
Epoch: [23][200/391]	Time  0.199 ( 0.266)	Data  0.001 ( 0.004)	Loss 4.8823e-01 (4.8113e-01)	Acc@1  85.16 ( 83.22)
Epoch: [23][300/391]	Time  0.601 ( 0.259)	Data  0.003 ( 0.003)	Loss 6.7045e-01 (4.8263e-01)	Acc@1  75.78 ( 83.13)
Train acc: 83.23, Train loss: 0.47983507095336914, Epoch time: 100.61492443084717
Test Epoch: [23][  0/100]	Time  0.358 ( 0.358)	Data  0.278 ( 0.278)	Loss 4.3013e-01 (4.3013e-01)	Acc@1  86.00 ( 86.00)
Current acc: 82.2, Current loss: 0.5215027855336666, best acc: 82.38, Test time: 10.36097502708435

Train Epoch: 24
Epoch: [24][  0/391]	Time  0.401 ( 0.401)	Data  0.230 ( 0.230)	Loss 5.7357e-01 (5.7357e-01)	Acc@1  79.69 ( 79.69)
Epoch: [24][100/391]	Time  0.159 ( 0.253)	Data  0.001 ( 0.004)	Loss 3.0370e-01 (4.5952e-01)	Acc@1  89.84 ( 84.11)
Epoch: [24][200/391]	Time  0.255 ( 0.249)	Data  0.001 ( 0.003)	Loss 5.8107e-01 (4.6164e-01)	Acc@1  77.34 ( 83.92)
Epoch: [24][300/391]	Time  0.206 ( 0.250)	Data  0.001 ( 0.003)	Loss 5.1131e-01 (4.6338e-01)	Acc@1  81.25 ( 83.71)
Train acc: 83.578, Train loss: 0.4677949544143677, Epoch time: 95.81830382347107
Test Epoch: [24][  0/100]	Time  0.351 ( 0.351)	Data  0.307 ( 0.307)	Loss 5.5754e-01 (5.5754e-01)	Acc@1  80.00 ( 80.00)
Current acc: 81.87, Current loss: 0.5368551117181778, best acc: 82.38, Test time: 10.207993268966675

Train Epoch: 25
Epoch: [25][  0/391]	Time  0.764 ( 0.764)	Data  0.189 ( 0.189)	Loss 5.9539e-01 (5.9539e-01)	Acc@1  80.47 ( 80.47)
Epoch: [25][100/391]	Time  0.148 ( 0.246)	Data  0.001 ( 0.004)	Loss 6.2647e-01 (4.5460e-01)	Acc@1  79.69 ( 84.03)
Epoch: [25][200/391]	Time  0.747 ( 0.250)	Data  0.002 ( 0.003)	Loss 4.1284e-01 (4.5990e-01)	Acc@1  84.38 ( 83.99)
Epoch: [25][300/391]	Time  0.110 ( 0.249)	Data  0.001 ( 0.003)	Loss 5.8672e-01 (4.5844e-01)	Acc@1  82.03 ( 83.98)
Train acc: 84.008, Train loss: 0.4582657758331299, Epoch time: 96.60390329360962
Test Epoch: [25][  0/100]	Time  0.243 ( 0.243)	Data  0.204 ( 0.204)	Loss 4.3076e-01 (4.3076e-01)	Acc@1  87.00 ( 87.00)
Current acc: 82.26, Current loss: 0.5217525005340576, best acc: 82.38, Test time: 10.106750011444092

Train Epoch: 26
Epoch: [26][  0/391]	Time  0.541 ( 0.541)	Data  0.225 ( 0.225)	Loss 5.2856e-01 (5.2856e-01)	Acc@1  82.81 ( 82.81)
Epoch: [26][100/391]	Time  0.158 ( 0.244)	Data  0.003 ( 0.005)	Loss 5.7666e-01 (4.4977e-01)	Acc@1  80.47 ( 84.28)
Epoch: [26][200/391]	Time  0.671 ( 0.247)	Data  0.003 ( 0.004)	Loss 3.6829e-01 (4.4597e-01)	Acc@1  88.28 ( 84.45)
Epoch: [26][300/391]	Time  0.176 ( 0.245)	Data  0.002 ( 0.003)	Loss 4.4383e-01 (4.4291e-01)	Acc@1  84.38 ( 84.43)
Train acc: 84.354, Train loss: 0.4470699811458588, Epoch time: 95.75948357582092
Test Epoch: [26][  0/100]	Time  0.288 ( 0.288)	Data  0.214 ( 0.214)	Loss 5.9228e-01 (5.9228e-01)	Acc@1  78.00 ( 78.00)
Current acc: 82.17, Current loss: 0.5262573401629925, best acc: 82.38, Test time: 9.46615481376648

Train Epoch: 27
Epoch: [27][  0/391]	Time  0.392 ( 0.392)	Data  0.198 ( 0.198)	Loss 3.3884e-01 (3.3884e-01)	Acc@1  89.06 ( 89.06)
Epoch: [27][100/391]	Time  0.443 ( 0.239)	Data  0.001 ( 0.005)	Loss 3.8825e-01 (4.4662e-01)	Acc@1  88.28 ( 84.41)
Epoch: [27][200/391]	Time  0.169 ( 0.248)	Data  0.002 ( 0.003)	Loss 5.1180e-01 (4.4196e-01)	Acc@1  85.94 ( 84.50)
Epoch: [27][300/391]	Time  0.401 ( 0.248)	Data  0.002 ( 0.003)	Loss 5.2897e-01 (4.4371e-01)	Acc@1  81.25 ( 84.41)
Train acc: 84.392, Train loss: 0.4431732238960266, Epoch time: 97.46592807769775
Test Epoch: [27][  0/100]	Time  0.365 ( 0.365)	Data  0.290 ( 0.290)	Loss 4.4652e-01 (4.4652e-01)	Acc@1  81.00 ( 81.00)
Current acc: 81.28, Current loss: 0.5526363563537597, best acc: 82.38, Test time: 9.653381586074829

Train Epoch: 28
Epoch: [28][  0/391]	Time  0.908 ( 0.908)	Data  0.207 ( 0.207)	Loss 4.8772e-01 (4.8772e-01)	Acc@1  83.59 ( 83.59)
Epoch: [28][100/391]	Time  0.130 ( 0.266)	Data  0.001 ( 0.004)	Loss 4.4004e-01 (4.2826e-01)	Acc@1  86.72 ( 84.94)
Epoch: [28][200/391]	Time  0.374 ( 0.261)	Data  0.001 ( 0.004)	Loss 4.3176e-01 (4.3026e-01)	Acc@1  82.81 ( 84.99)
Epoch: [28][300/391]	Time  0.506 ( 0.258)	Data  0.002 ( 0.003)	Loss 4.3381e-01 (4.3128e-01)	Acc@1  83.59 ( 84.88)
Train acc: 84.86, Train loss: 0.43167202909469604, Epoch time: 99.82289004325867
Test Epoch: [28][  0/100]	Time  0.441 ( 0.441)	Data  0.373 ( 0.373)	Loss 4.1282e-01 (4.1282e-01)	Acc@1  84.00 ( 84.00)
Saving...
Current acc: 83.22, Current loss: 0.5132871608436108, best acc: 83.22, Test time: 10.202239990234375

Train Epoch: 29
Epoch: [29][  0/391]	Time  0.552 ( 0.552)	Data  0.262 ( 0.262)	Loss 3.4649e-01 (3.4649e-01)	Acc@1  88.28 ( 88.28)
Epoch: [29][100/391]	Time  0.303 ( 0.258)	Data  0.002 ( 0.005)	Loss 4.4288e-01 (4.2024e-01)	Acc@1  84.38 ( 85.61)
Epoch: [29][200/391]	Time  0.136 ( 0.247)	Data  0.005 ( 0.004)	Loss 5.7268e-01 (4.2052e-01)	Acc@1  81.25 ( 85.41)
Epoch: [29][300/391]	Time  0.136 ( 0.240)	Data  0.001 ( 0.003)	Loss 4.8932e-01 (4.2077e-01)	Acc@1  85.94 ( 85.42)
Train acc: 85.38, Train loss: 0.4229543848800659, Epoch time: 93.140300989151
Test Epoch: [29][  0/100]	Time  0.255 ( 0.255)	Data  0.198 ( 0.198)	Loss 3.7161e-01 (3.7161e-01)	Acc@1  87.00 ( 87.00)
Current acc: 82.15, Current loss: 0.5381280694901943, best acc: 83.22, Test time: 9.301071882247925

Train Epoch: 30
Epoch: [30][  0/391]	Time  0.370 ( 0.370)	Data  0.238 ( 0.238)	Loss 5.5093e-01 (5.5093e-01)	Acc@1  80.47 ( 80.47)
Epoch: [30][100/391]	Time  0.134 ( 0.253)	Data  0.001 ( 0.004)	Loss 3.3248e-01 (4.2065e-01)	Acc@1  87.50 ( 85.17)
Epoch: [30][200/391]	Time  0.333 ( 0.249)	Data  0.002 ( 0.003)	Loss 3.5023e-01 (4.2042e-01)	Acc@1  86.72 ( 85.20)
Epoch: [30][300/391]	Time  0.152 ( 0.243)	Data  0.001 ( 0.003)	Loss 3.8155e-01 (4.1670e-01)	Acc@1  86.72 ( 85.35)
Train acc: 85.246, Train loss: 0.4186347867870331, Epoch time: 94.66553831100464
Test Epoch: [30][  0/100]	Time  0.259 ( 0.259)	Data  0.191 ( 0.191)	Loss 3.9545e-01 (3.9545e-01)	Acc@1  88.00 ( 88.00)
Saving...
Current acc: 83.37, Current loss: 0.5030167698860168, best acc: 83.37, Test time: 9.50559377670288

Train Epoch: 31
Epoch: [31][  0/391]	Time  0.567 ( 0.567)	Data  0.216 ( 0.216)	Loss 4.0488e-01 (4.0488e-01)	Acc@1  85.94 ( 85.94)
Epoch: [31][100/391]	Time  0.160 ( 0.256)	Data  0.002 ( 0.004)	Loss 5.4749e-01 (3.9470e-01)	Acc@1  84.38 ( 86.14)
Epoch: [31][200/391]	Time  0.750 ( 0.252)	Data  0.002 ( 0.003)	Loss 3.6566e-01 (4.0378e-01)	Acc@1  92.97 ( 85.84)
Epoch: [31][300/391]	Time  0.206 ( 0.254)	Data  0.001 ( 0.003)	Loss 5.3306e-01 (4.0715e-01)	Acc@1  82.03 ( 85.66)
Train acc: 85.598, Train loss: 0.4108138609695435, Epoch time: 99.05935716629028
Test Epoch: [31][  0/100]	Time  0.215 ( 0.215)	Data  0.156 ( 0.156)	Loss 3.7816e-01 (3.7816e-01)	Acc@1  88.00 ( 88.00)
Current acc: 83.19, Current loss: 0.5033730205893516, best acc: 83.37, Test time: 9.27309775352478

Train Epoch: 32
Epoch: [32][  0/391]	Time  0.464 ( 0.464)	Data  0.192 ( 0.192)	Loss 3.8565e-01 (3.8565e-01)	Acc@1  83.59 ( 83.59)
Epoch: [32][100/391]	Time  0.157 ( 0.244)	Data  0.001 ( 0.004)	Loss 5.1299e-01 (3.8870e-01)	Acc@1  82.03 ( 86.46)
Epoch: [32][200/391]	Time  0.126 ( 0.239)	Data  0.001 ( 0.003)	Loss 4.1715e-01 (4.0002e-01)	Acc@1  83.59 ( 86.13)
Epoch: [32][300/391]	Time  0.260 ( 0.243)	Data  0.001 ( 0.003)	Loss 4.4206e-01 (4.0006e-01)	Acc@1  82.03 ( 86.11)
Train acc: 85.878, Train loss: 0.40601171578407286, Epoch time: 95.63639688491821
Test Epoch: [32][  0/100]	Time  0.190 ( 0.190)	Data  0.143 ( 0.143)	Loss 4.4402e-01 (4.4402e-01)	Acc@1  85.00 ( 85.00)
Saving...
Current acc: 84.4, Current loss: 0.4552903510630131, best acc: 84.4, Test time: 8.856561422348022

Train Epoch: 33
Epoch: [33][  0/391]	Time  0.966 ( 0.966)	Data  0.204 ( 0.204)	Loss 2.9537e-01 (2.9537e-01)	Acc@1  92.97 ( 92.97)
Epoch: [33][100/391]	Time  0.154 ( 0.256)	Data  0.002 ( 0.004)	Loss 5.5652e-01 (3.8101e-01)	Acc@1  78.12 ( 86.70)
Epoch: [33][200/391]	Time  0.223 ( 0.248)	Data  0.001 ( 0.003)	Loss 4.0416e-01 (3.8622e-01)	Acc@1  88.28 ( 86.39)
Epoch: [33][300/391]	Time  0.155 ( 0.247)	Data  0.003 ( 0.003)	Loss 3.4001e-01 (3.9393e-01)	Acc@1  88.28 ( 86.09)
Train acc: 86.218, Train loss: 0.3928429799079895, Epoch time: 95.68165135383606
Test Epoch: [33][  0/100]	Time  0.241 ( 0.241)	Data  0.188 ( 0.188)	Loss 4.8488e-01 (4.8488e-01)	Acc@1  86.00 ( 86.00)
Current acc: 83.45, Current loss: 0.505477756857872, best acc: 84.4, Test time: 9.996539831161499

Train Epoch: 34
Epoch: [34][  0/391]	Time  0.591 ( 0.591)	Data  0.421 ( 0.421)	Loss 4.7034e-01 (4.7034e-01)	Acc@1  83.59 ( 83.59)
Epoch: [34][100/391]	Time  0.166 ( 0.252)	Data  0.014 ( 0.006)	Loss 3.9018e-01 (3.8112e-01)	Acc@1  87.50 ( 86.70)
Epoch: [34][200/391]	Time  0.156 ( 0.256)	Data  0.001 ( 0.004)	Loss 3.4832e-01 (3.9823e-01)	Acc@1  88.28 ( 85.99)
Epoch: [34][300/391]	Time  0.717 ( 0.258)	Data  0.001 ( 0.004)	Loss 2.7839e-01 (3.9326e-01)	Acc@1  89.84 ( 86.19)
Train acc: 86.376, Train loss: 0.3892953106880188, Epoch time: 99.78653621673584
Test Epoch: [34][  0/100]	Time  0.311 ( 0.311)	Data  0.274 ( 0.274)	Loss 3.4718e-01 (3.4718e-01)	Acc@1  87.00 ( 87.00)
Saving...
Current acc: 85.26, Current loss: 0.442101968228817, best acc: 85.26, Test time: 10.60659670829773

Train Epoch: 35
Epoch: [35][  0/391]	Time  0.396 ( 0.396)	Data  0.221 ( 0.221)	Loss 2.4768e-01 (2.4768e-01)	Acc@1  91.41 ( 91.41)
Epoch: [35][100/391]	Time  0.143 ( 0.240)	Data  0.001 ( 0.004)	Loss 4.7596e-01 (3.8207e-01)	Acc@1  85.16 ( 86.20)
Epoch: [35][200/391]	Time  0.306 ( 0.242)	Data  0.001 ( 0.003)	Loss 3.6514e-01 (3.8056e-01)	Acc@1  85.94 ( 86.40)
Epoch: [35][300/391]	Time  0.171 ( 0.243)	Data  0.006 ( 0.003)	Loss 2.8696e-01 (3.7849e-01)	Acc@1  91.41 ( 86.58)
Train acc: 86.622, Train loss: 0.38047071434020996, Epoch time: 95.19122767448425
Test Epoch: [35][  0/100]	Time  0.246 ( 0.246)	Data  0.185 ( 0.185)	Loss 3.4733e-01 (3.4733e-01)	Acc@1  86.00 ( 86.00)
Current acc: 84.16, Current loss: 0.4676040497422218, best acc: 85.26, Test time: 10.327199935913086

Train Epoch: 36
Epoch: [36][  0/391]	Time  0.424 ( 0.424)	Data  0.253 ( 0.253)	Loss 3.7391e-01 (3.7391e-01)	Acc@1  85.16 ( 85.16)
Epoch: [36][100/391]	Time  0.153 ( 0.247)	Data  0.002 ( 0.004)	Loss 2.9417e-01 (3.6638e-01)	Acc@1  90.62 ( 86.98)
Epoch: [36][200/391]	Time  0.155 ( 0.246)	Data  0.001 ( 0.003)	Loss 4.1811e-01 (3.6801e-01)	Acc@1  85.94 ( 87.14)
Epoch: [36][300/391]	Time  0.369 ( 0.244)	Data  0.002 ( 0.003)	Loss 4.0794e-01 (3.7716e-01)	Acc@1  85.16 ( 86.76)
Train acc: 86.694, Train loss: 0.37892490502357484, Epoch time: 94.9721896648407
Test Epoch: [36][  0/100]	Time  0.278 ( 0.278)	Data  0.225 ( 0.225)	Loss 4.1918e-01 (4.1918e-01)	Acc@1  85.00 ( 85.00)
Current acc: 84.23, Current loss: 0.461987147629261, best acc: 85.26, Test time: 8.359304904937744

Train Epoch: 37
Epoch: [37][  0/391]	Time  0.682 ( 0.682)	Data  0.255 ( 0.255)	Loss 3.1101e-01 (3.1101e-01)	Acc@1  89.84 ( 89.84)
Epoch: [37][100/391]	Time  0.163 ( 0.236)	Data  0.003 ( 0.004)	Loss 2.6693e-01 (3.6796e-01)	Acc@1  89.84 ( 87.04)
Epoch: [37][200/391]	Time  0.545 ( 0.245)	Data  0.002 ( 0.003)	Loss 3.3728e-01 (3.6791e-01)	Acc@1  86.72 ( 87.23)
Epoch: [37][300/391]	Time  0.148 ( 0.244)	Data  0.001 ( 0.003)	Loss 4.1320e-01 (3.6659e-01)	Acc@1  84.38 ( 87.25)
Train acc: 87.174, Train loss: 0.3678389298725128, Epoch time: 96.50201916694641
Test Epoch: [37][  0/100]	Time  0.280 ( 0.280)	Data  0.230 ( 0.230)	Loss 3.9402e-01 (3.9402e-01)	Acc@1  84.00 ( 84.00)
Current acc: 83.49, Current loss: 0.48868497878313066, best acc: 85.26, Test time: 10.271829843521118

Train Epoch: 38
Epoch: [38][  0/391]	Time  0.409 ( 0.409)	Data  0.264 ( 0.264)	Loss 4.2902e-01 (4.2902e-01)	Acc@1  85.16 ( 85.16)
Epoch: [38][100/391]	Time  0.148 ( 0.245)	Data  0.001 ( 0.005)	Loss 3.2243e-01 (3.6190e-01)	Acc@1  89.06 ( 87.19)
Epoch: [38][200/391]	Time  0.134 ( 0.245)	Data  0.002 ( 0.004)	Loss 2.1506e-01 (3.6639e-01)	Acc@1  90.62 ( 87.17)
Epoch: [38][300/391]	Time  0.156 ( 0.244)	Data  0.006 ( 0.003)	Loss 4.1351e-01 (3.7386e-01)	Acc@1  85.94 ( 86.88)
Train acc: 86.882, Train loss: 0.3756876551437378, Epoch time: 94.68283414840698
Test Epoch: [38][  0/100]	Time  0.255 ( 0.255)	Data  0.199 ( 0.199)	Loss 3.3231e-01 (3.3231e-01)	Acc@1  86.00 ( 86.00)
Current acc: 84.74, Current loss: 0.4638379581272602, best acc: 85.26, Test time: 10.364039182662964

Train Epoch: 39
Epoch: [39][  0/391]	Time  0.391 ( 0.391)	Data  0.193 ( 0.193)	Loss 2.6762e-01 (2.6762e-01)	Acc@1  91.41 ( 91.41)
Epoch: [39][100/391]	Time  0.159 ( 0.236)	Data  0.006 ( 0.004)	Loss 4.0790e-01 (3.4580e-01)	Acc@1  83.59 ( 87.64)
Epoch: [39][200/391]	Time  0.164 ( 0.241)	Data  0.003 ( 0.003)	Loss 2.6327e-01 (3.5573e-01)	Acc@1  90.62 ( 87.45)
Epoch: [39][300/391]	Time  0.182 ( 0.242)	Data  0.002 ( 0.003)	Loss 4.4314e-01 (3.5857e-01)	Acc@1  85.94 ( 87.41)
Train acc: 87.374, Train loss: 0.3614129730033874, Epoch time: 94.2405035495758
Test Epoch: [39][  0/100]	Time  0.214 ( 0.214)	Data  0.173 ( 0.173)	Loss 3.9310e-01 (3.9310e-01)	Acc@1  85.00 ( 85.00)
Current acc: 85.05, Current loss: 0.4502232141792774, best acc: 85.26, Test time: 9.656296014785767

Train Epoch: 40
Epoch: [40][  0/391]	Time  0.380 ( 0.380)	Data  0.197 ( 0.197)	Loss 2.9259e-01 (2.9259e-01)	Acc@1  89.84 ( 89.84)
Epoch: [40][100/391]	Time  0.217 ( 0.265)	Data  0.002 ( 0.004)	Loss 3.6835e-01 (3.4820e-01)	Acc@1  86.72 ( 88.04)
Epoch: [40][200/391]	Time  0.194 ( 0.258)	Data  0.002 ( 0.003)	Loss 3.4140e-01 (3.4765e-01)	Acc@1  88.28 ( 87.89)
Epoch: [40][300/391]	Time  0.131 ( 0.255)	Data  0.001 ( 0.003)	Loss 4.3648e-01 (3.5659e-01)	Acc@1  85.16 ( 87.51)
Train acc: 87.346, Train loss: 0.3597674360370636, Epoch time: 97.82172918319702
Test Epoch: [40][  0/100]	Time  0.358 ( 0.358)	Data  0.270 ( 0.270)	Loss 4.6847e-01 (4.6847e-01)	Acc@1  87.00 ( 87.00)
Current acc: 85.21, Current loss: 0.439174881875515, best acc: 85.26, Test time: 9.808207035064697

Train Epoch: 41
Epoch: [41][  0/391]	Time  0.544 ( 0.544)	Data  0.264 ( 0.264)	Loss 4.1464e-01 (4.1464e-01)	Acc@1  83.59 ( 83.59)
Epoch: [41][100/391]	Time  0.132 ( 0.246)	Data  0.002 ( 0.004)	Loss 4.0366e-01 (3.5349e-01)	Acc@1  87.50 ( 87.96)
Epoch: [41][200/391]	Time  0.164 ( 0.242)	Data  0.001 ( 0.004)	Loss 2.7048e-01 (3.5204e-01)	Acc@1  88.28 ( 87.82)
Epoch: [41][300/391]	Time  0.135 ( 0.244)	Data  0.003 ( 0.003)	Loss 2.4170e-01 (3.5228e-01)	Acc@1  92.97 ( 87.70)
Train acc: 87.586, Train loss: 0.35436033619880675, Epoch time: 96.48945713043213
Test Epoch: [41][  0/100]	Time  0.344 ( 0.344)	Data  0.248 ( 0.248)	Loss 4.0783e-01 (4.0783e-01)	Acc@1  88.00 ( 88.00)
Current acc: 85.21, Current loss: 0.4476769642531872, best acc: 85.26, Test time: 10.341238737106323

Train Epoch: 42
Epoch: [42][  0/391]	Time  0.411 ( 0.411)	Data  0.251 ( 0.251)	Loss 3.7917e-01 (3.7917e-01)	Acc@1  85.16 ( 85.16)
Epoch: [42][100/391]	Time  0.149 ( 0.248)	Data  0.002 ( 0.005)	Loss 3.7716e-01 (3.3816e-01)	Acc@1  88.28 ( 88.44)
Epoch: [42][200/391]	Time  0.205 ( 0.243)	Data  0.002 ( 0.004)	Loss 4.9385e-01 (3.4692e-01)	Acc@1  84.38 ( 88.02)
Epoch: [42][300/391]	Time  0.144 ( 0.244)	Data  0.002 ( 0.003)	Loss 3.8448e-01 (3.4882e-01)	Acc@1  84.38 ( 87.93)
Train acc: 87.834, Train loss: 0.34956454584121704, Epoch time: 95.14836192131042
Test Epoch: [42][  0/100]	Time  0.206 ( 0.206)	Data  0.166 ( 0.166)	Loss 3.8835e-01 (3.8835e-01)	Acc@1  87.00 ( 87.00)
Saving...
Current acc: 85.51, Current loss: 0.43674387320876124, best acc: 85.51, Test time: 9.95382046699524

Train Epoch: 43
Epoch: [43][  0/391]	Time  0.715 ( 0.715)	Data  0.192 ( 0.192)	Loss 3.7754e-01 (3.7754e-01)	Acc@1  85.94 ( 85.94)
Epoch: [43][100/391]	Time  0.192 ( 0.255)	Data  0.003 ( 0.004)	Loss 4.4977e-01 (3.2650e-01)	Acc@1  82.03 ( 88.50)
Epoch: [43][200/391]	Time  0.124 ( 0.247)	Data  0.002 ( 0.003)	Loss 2.6798e-01 (3.3947e-01)	Acc@1  90.62 ( 88.25)
Epoch: [43][300/391]	Time  0.109 ( 0.247)	Data  0.002 ( 0.003)	Loss 3.2374e-01 (3.4042e-01)	Acc@1  89.06 ( 88.12)
Train acc: 87.898, Train loss: 0.34643793937683104, Epoch time: 96.41564321517944
Test Epoch: [43][  0/100]	Time  0.200 ( 0.200)	Data  0.138 ( 0.138)	Loss 3.2847e-01 (3.2847e-01)	Acc@1  88.00 ( 88.00)
Current acc: 85.07, Current loss: 0.44820560693740846, best acc: 85.51, Test time: 9.748414754867554

Train Epoch: 44
Epoch: [44][  0/391]	Time  0.449 ( 0.449)	Data  0.255 ( 0.255)	Loss 2.9698e-01 (2.9698e-01)	Acc@1  87.50 ( 87.50)
Epoch: [44][100/391]	Time  0.155 ( 0.237)	Data  0.002 ( 0.005)	Loss 4.4653e-01 (3.3716e-01)	Acc@1  82.81 ( 88.00)
Epoch: [44][200/391]	Time  0.167 ( 0.247)	Data  0.003 ( 0.003)	Loss 4.3341e-01 (3.3718e-01)	Acc@1  85.94 ( 88.15)
Epoch: [44][300/391]	Time  0.207 ( 0.242)	Data  0.006 ( 0.003)	Loss 3.1099e-01 (3.3554e-01)	Acc@1  89.06 ( 88.25)
Train acc: 88.244, Train loss: 0.337373899230957, Epoch time: 94.26191020011902
Test Epoch: [44][  0/100]	Time  0.225 ( 0.225)	Data  0.185 ( 0.185)	Loss 3.2987e-01 (3.2987e-01)	Acc@1  86.00 ( 86.00)
Saving...
Current acc: 85.65, Current loss: 0.44055815160274503, best acc: 85.65, Test time: 9.641561508178711

Train Epoch: 45
Epoch: [45][  0/391]	Time  0.725 ( 0.725)	Data  0.254 ( 0.254)	Loss 4.8487e-01 (4.8487e-01)	Acc@1  84.38 ( 84.38)
Epoch: [45][100/391]	Time  0.382 ( 0.238)	Data  0.002 ( 0.005)	Loss 3.0465e-01 (3.3150e-01)	Acc@1  89.84 ( 88.20)
Epoch: [45][200/391]	Time  0.154 ( 0.231)	Data  0.002 ( 0.003)	Loss 2.7471e-01 (3.3944e-01)	Acc@1  92.19 ( 88.03)
Epoch: [45][300/391]	Time  0.147 ( 0.236)	Data  0.001 ( 0.003)	Loss 3.0507e-01 (3.4082e-01)	Acc@1  86.72 ( 87.99)
Train acc: 87.94, Train loss: 0.3428226525306702, Epoch time: 92.51655960083008
Test Epoch: [45][  0/100]	Time  0.244 ( 0.244)	Data  0.152 ( 0.152)	Loss 4.0290e-01 (4.0290e-01)	Acc@1  84.00 ( 84.00)
Current acc: 85.09, Current loss: 0.449273736923933, best acc: 85.65, Test time: 9.732155799865723

Train Epoch: 46
Epoch: [46][  0/391]	Time  0.391 ( 0.391)	Data  0.237 ( 0.237)	Loss 2.2549e-01 (2.2549e-01)	Acc@1  91.41 ( 91.41)
Epoch: [46][100/391]	Time  0.154 ( 0.236)	Data  0.002 ( 0.004)	Loss 4.2733e-01 (3.3609e-01)	Acc@1  86.72 ( 88.20)
Epoch: [46][200/391]	Time  0.554 ( 0.241)	Data  0.001 ( 0.003)	Loss 2.8455e-01 (3.2663e-01)	Acc@1  89.06 ( 88.48)
Epoch: [46][300/391]	Time  0.360 ( 0.243)	Data  0.001 ( 0.003)	Loss 3.8168e-01 (3.3191e-01)	Acc@1  85.94 ( 88.37)
Train acc: 88.28, Train loss: 0.3346131315803528, Epoch time: 94.84503984451294
Test Epoch: [46][  0/100]	Time  0.229 ( 0.229)	Data  0.188 ( 0.188)	Loss 4.2492e-01 (4.2492e-01)	Acc@1  88.00 ( 88.00)
Saving...
Current acc: 85.73, Current loss: 0.4424561692774296, best acc: 85.73, Test time: 9.414117097854614

Train Epoch: 47
Epoch: [47][  0/391]	Time  0.641 ( 0.641)	Data  0.229 ( 0.229)	Loss 3.4035e-01 (3.4035e-01)	Acc@1  85.16 ( 85.16)
Epoch: [47][100/391]	Time  0.203 ( 0.247)	Data  0.002 ( 0.005)	Loss 3.7471e-01 (3.4076e-01)	Acc@1  87.50 ( 88.31)
Epoch: [47][200/391]	Time  0.142 ( 0.249)	Data  0.002 ( 0.004)	Loss 3.1170e-01 (3.3673e-01)	Acc@1  90.62 ( 88.31)
Epoch: [47][300/391]	Time  0.495 ( 0.245)	Data  0.001 ( 0.003)	Loss 2.2596e-01 (3.3285e-01)	Acc@1  91.41 ( 88.35)
Train acc: 88.346, Train loss: 0.3337341605377197, Epoch time: 95.2448935508728
Test Epoch: [47][  0/100]	Time  0.320 ( 0.320)	Data  0.249 ( 0.249)	Loss 3.4223e-01 (3.4223e-01)	Acc@1  89.00 ( 89.00)
Current acc: 85.31, Current loss: 0.43531294479966165, best acc: 85.73, Test time: 9.806842803955078

Train Epoch: 48
Epoch: [48][  0/391]	Time  0.521 ( 0.521)	Data  0.307 ( 0.307)	Loss 2.3513e-01 (2.3513e-01)	Acc@1  92.19 ( 92.19)
Epoch: [48][100/391]	Time  0.161 ( 0.251)	Data  0.002 ( 0.005)	Loss 2.5377e-01 (3.0678e-01)	Acc@1  89.84 ( 89.07)
Epoch: [48][200/391]	Time  0.144 ( 0.253)	Data  0.001 ( 0.004)	Loss 3.7037e-01 (3.1797e-01)	Acc@1  85.94 ( 88.79)
Epoch: [48][300/391]	Time  0.204 ( 0.255)	Data  0.002 ( 0.003)	Loss 3.0248e-01 (3.2508e-01)	Acc@1  89.84 ( 88.63)
Train acc: 88.6, Train loss: 0.3282761324501038, Epoch time: 99.90585422515869
Test Epoch: [48][  0/100]	Time  0.250 ( 0.250)	Data  0.199 ( 0.199)	Loss 3.6875e-01 (3.6875e-01)	Acc@1  91.00 ( 91.00)
Current acc: 85.21, Current loss: 0.4408486729860306, best acc: 85.73, Test time: 9.740058660507202

Train Epoch: 49
Epoch: [49][  0/391]	Time  0.778 ( 0.778)	Data  0.213 ( 0.213)	Loss 2.3679e-01 (2.3679e-01)	Acc@1  92.97 ( 92.97)
Epoch: [49][100/391]	Time  0.123 ( 0.244)	Data  0.001 ( 0.004)	Loss 4.1651e-01 (3.2309e-01)	Acc@1  85.94 ( 88.51)
Epoch: [49][200/391]	Time  0.183 ( 0.244)	Data  0.008 ( 0.003)	Loss 2.4698e-01 (3.2553e-01)	Acc@1  90.62 ( 88.53)
Epoch: [49][300/391]	Time  0.104 ( 0.242)	Data  0.002 ( 0.003)	Loss 2.3777e-01 (3.2834e-01)	Acc@1  90.62 ( 88.53)
Train acc: 88.368, Train loss: 0.33262564512252807, Epoch time: 93.9956111907959
Test Epoch: [49][  0/100]	Time  0.289 ( 0.289)	Data  0.237 ( 0.237)	Loss 3.9264e-01 (3.9264e-01)	Acc@1  86.00 ( 86.00)
Saving...
Current acc: 85.98, Current loss: 0.42809283956885336, best acc: 85.98, Test time: 8.637914180755615
